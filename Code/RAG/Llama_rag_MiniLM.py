
import os
import sys
import json
import chromadb
from unsloth import FastLanguageModel
from peft import PeftModel
from google.colab import drive

# ================= CONFIGURATION =================
PROJECT_ROOT = "/content/drive/MyDrive/RegulAItion"
DB_PATH = os.path.join(PROJECT_ROOT, "Data", "RAG_db_all")
ADAPTER_PATH = os.path.join(PROJECT_ROOT, "Models", "Llama3.1_adapter") 

# ================= SETUP =================
def setup_environment():
    print("ğŸš€ Initializing Environment...")
    if not os.path.exists('/content/drive'):
        drive.mount('/content/drive')

    if not os.path.exists(ADAPTER_PATH):
        alt = ADAPTER_PATH.replace("Llama", "llama")
        if os.path.exists(alt): return DB_PATH, alt
        raise FileNotFoundError(f"âŒ Adapter not found at {ADAPTER_PATH}")
    
    return DB_PATH, ADAPTER_PATH

# ================= LOAD SYSTEM =================
def load_system(db_path, adapter_path):
    print(f"â³ Loading Model...")
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name="unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        max_seq_length=2048,
        load_in_4bit=True,
    )
    model = PeftModel.from_pretrained(model, adapter_path)
    FastLanguageModel.for_inference(model)

    print(f"ğŸ§  Connecting to DB...")
    client = chromadb.PersistentClient(path=db_path)
    col = client.get_collection(name=client.list_collections()[0].name)
    
    return model, tokenizer, col

# ================= RETRIEVAL =================
def retrieve(col, query):
    res = col.query(query_texts=[query], n_results=3)
    context = []
    if res['documents']:
        for i, doc in enumerate(res['documents'][0]):
            meta = res['metadatas'][0][i]
            context.append(f"Source: {meta.get('source', 'UNK')} (Page {meta.get('page_label', '0')})\nText: {doc}")
    return "\n\n".join(context)

# ================= GENERATION (PRO PROMPT) =================
def generate(model, tokenizer, query, context):
    # ×¤×¨×•××¤×˜ ××©×•×¤×¨ ×•××§×¦×•×¢×™
    prompt = f"""### Instruction:
You are an expert regulatory compliance assistant. 
Your task is to answer the user's question based STRICTLY on the provided context.

Rules:
1. If the answer is explicitly supported by the text, return "verdict": "Yes" or "No".
2. If the answer is NOT found in the context, return "verdict": "N.A".
3. If verdict is "N.A", set "quote" to "N.A" and "source_details" to "N.A".
4. "quote" must be an EXACT copy of the relevant text segment.
5. Return ONLY a valid JSON object with keys: "verdict", "explanation", "quote", "source_details".

### Input:
Context:
{context}

Question:
{query}

### Response:
"""
    inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
    out = model.generate(**inputs, max_new_tokens=256, temperature=0.1)
    return tokenizer.batch_decode(out, skip_special_tokens=True)[0].split("### Response:")[-1].strip()

# ================= MAIN =================
def main():
    try:
        db_path, adapter_path = setup_environment()
        model, tokenizer, col = load_system(db_path, adapter_path)
        
        print("\nâœ… SYSTEM READY. ASKING QUESTIONS (PRO MODE)...\n")
        
        while True:
            q = input("â“ Question (or 'exit'): ")
            if q.lower() in ['exit', 'quit']: break
            
            ctx = retrieve(col, q)
            if not ctx: 
                print("âŒ DB returned no documents.")
                continue
                
            ans = generate(model, tokenizer, q, ctx)
            
            # ×”×“×¤×¡×ª ×“×™×‘××’
            # print(f"\nğŸ› DEBUG RAW OUTPUT:\n{ans}\n") 

            try:
                clean_json = ans[ans.find('{'):ans.rfind('}')+1]
                data = json.loads(clean_json)
                
                print("-" * 50)
                print(f"Verdict: {data.get('verdict')}")
                
                # ×ª×¦×•×’×” ×—×›××” ×™×•×ª×¨: ××¦×™×’ ×¦×™×˜×•×˜ ×•××§×•×¨ ×¨×§ ×× ×™×© ×ª×©×•×‘×”
                if data.get('verdict') != 'N.A':
                    print(f"Quote:   {data.get('quote')}")
                    src = data.get('source') or data.get('source_details') or "N/A"
                    print(f"Source:  {src}")
                else:
                    print(f"Quote:   N.A") # × ×§×™ ×™×•×ª×¨
                
                print(f"Explain: {data.get('explanation')}")
                print("-" * 50)
            except:
                print("âš ï¸ JSON Error. Raw output:", ans)

    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main()
